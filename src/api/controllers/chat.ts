import _ from "lodash";
import { PassThrough } from "stream";

import APIException from "@/lib/exceptions/APIException.ts";
import EX from "@/api/consts/exceptions.ts";
import logger from "@/lib/logger.ts";
import util from "@/lib/util.ts";
import { generateImages, DEFAULT_MODEL } from "./images.ts";
import { generateVideo, DEFAULT_VIDEO_MODEL } from "./videos.ts";

// æœ€å¤§é‡è¯•æ¬¡æ•°
const MAX_RETRY_COUNT = 3;
// é‡è¯•å»¶è¿Ÿ
const RETRY_DELAY = 5000;

/**
 * åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘æ¨¡å‹
 */
function isVideoModel(model: string): boolean {
  return model.startsWith("jimeng-video-");
}

/**
 * è§£ææ¨¡å‹
 *
 * @param model æ¨¡å‹åç§°
 * @returns æ¨¡å‹ä¿¡æ¯
 */
function parseModel(model: string) {
  const [_model, size] = model.split(":");

  if (!size) {
    // 4.0 æ¨¡å‹é»˜è®¤ä½¿ç”¨ 2k å°ºå¯¸
    const is4_0Model = _model.includes("4.0");
    // 3.x æ¨¡å‹é»˜è®¤ä½¿ç”¨ 2k å°ºå¯¸
    const is3_xModel = _model.includes("3.");

    let defaultDimension = 1024;
    if (is4_0Model) {
      defaultDimension = 4096;
    } else if (is3_xModel) {
      defaultDimension = 2048;
    }

    return {
      model: _model,
      width: defaultDimension,
      height: defaultDimension,
    };
  }

  // å¤„ç† 1k, 2k, 4k æ ¼å¼
  const kMatch = /^(\d+)k$/i.exec(size);
  if (kMatch) {
    const k = parseInt(kMatch[1]);
    const dimension = k * 1024;
    return {
      model: _model,
      width: dimension,
      height: dimension,
    };
  }

  // å¤„ç†ä¼ ç»Ÿçš„ widthxheight æ ¼å¼
  const [_, width, height] = /(\d+)[\W\w](\d+)/.exec(size) ?? [];
  return {
    model: _model,
    width: width ? Math.ceil(parseInt(width) / 2) * 2 : 1024,
    height: height ? Math.ceil(parseInt(height) / 2) * 2 : 1024,
  };
}

/**
 * è§£æ OpenAI é£æ ¼æ¶ˆæ¯ï¼Œæå–æ–‡æœ¬ä¸æ‰€æœ‰å›¾ç‰‡ URL
 */
function parseOpenAIMessageContent(content: any): { text: string; images?: string[] } {
  if (_.isString(content)) return { text: content };
  if (_.isArray(content)) {
    let textParts: string[] = [];
    let images: string[] = [];
    for (const item of content) {
      if (item?.type === "text" && _.isString(item?.text)) {
        textParts.push(item.text);
      } else if (
        item?.type === "image_url" &&
        item?.image_url &&
        _.isString(item?.image_url?.url)
      ) {
        images.push(item.image_url.url);
      }
    }
    return { text: textParts.join(""), images: images.length > 0 ? images : undefined };
  }
  if (_.isObject(content) && _.isString((content as any).content)) return { text: (content as any).content };
  return { text: "" };
}

/**
 * åŒæ­¥å¯¹è¯è¡¥å…¨
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨jimengåŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletion(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  return (async () => {
    if (messages.length === 0)
      throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º");

    // è§£ææœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒ text + image_url
    const last = messages[messages.length - 1];
    const { text: promptText, images } = parseOpenAIMessageContent(last?.content);

    // åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘æ¨¡å‹
    if (isVideoModel(_model)) {
      logger.info("æ£€æµ‹åˆ°è§†é¢‘æ¨¡å‹ï¼Œä½¿ç”¨è§†é¢‘ç”Ÿæˆ");

      // è§†é¢‘ç”Ÿæˆéœ€è¦é¦–å¸§å›¾ç‰‡
      if (!images || images.length === 0) {
        throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "è§†é¢‘ç”Ÿæˆéœ€è¦æä¾›é¦–å¸§å›¾ç‰‡");
      }

      // æ”¯æŒé¦–å°¾å¸§æ¨¡å¼ï¼šå¦‚æœæä¾›äº†ä¸¤å¼ å›¾ç‰‡ï¼Œç¬¬äºŒå¼ ä½œä¸ºç»“æŸå¸§
      const videoParams: any = {
        firstFrameImage: images[0],
      };
      
      if (images.length >= 2) {
        videoParams.endFrameImage = images[1];
        logger.info(`æ£€æµ‹åˆ° ${images.length} å¼ å›¾ç‰‡ï¼Œä½¿ç”¨é¦–å°¾å¸§æ¨¡å¼`);
      } else {
        logger.info("ä»…æä¾›äº†1å¼ å›¾ç‰‡ï¼Œä½¿ç”¨é¦–å¸§æ¨¡å¼");
      }
      
      if (images.length > 2) {
        logger.warn(`æä¾›äº† ${images.length} å¼ å›¾ç‰‡ï¼Œä½†è§†é¢‘ç”Ÿæˆæœ€å¤šæ”¯æŒ2å¼ ï¼ˆé¦–å¸§+å°¾å¸§ï¼‰ï¼Œå…¶ä½™å›¾ç‰‡å°†è¢«å¿½ç•¥`);
      }

      const videoUrls = await generateVideo(
        _model,
        promptText,
        videoParams,
        refreshToken
      );

      return {
        id: util.uuid(),
        model: _model,
        object: "chat.completion",
        choices: [
          {
            index: 0,
            message: {
              role: "assistant",
              content: videoUrls.reduce(
                (acc, url, i) => acc + `<video controls="controls">\n    ${url}\n</video>\n\n[Download Video](${url})\n\n`,
                ""
              ),
            },
            finish_reason: "stop",
          },
        ],
        usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
        created: util.unixTimestamp(),
      };
    }

    // å›¾åƒç”Ÿæˆ
    const { model, width, height } = parseModel(_model);
    logger.info(messages);

    const imageUrls = await generateImages(
      model,
      promptText,
      {
        width,
        height,
        images,
      },
      refreshToken
    );

    return {
      id: util.uuid(),
      model: _model || model,
      object: "chat.completion",
      choices: [
        {
          index: 0,
          message: {
            role: "assistant",
            content: imageUrls.reduce(
              (acc, url, i) => acc + `![image_${i}](${url})\n`,
              ""
            ),
          },
          finish_reason: "stop",
        },
      ],
      usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
      created: util.unixTimestamp(),
    };
  })().catch((err) => {
    if (retryCount < MAX_RETRY_COUNT) {
      logger.error(`Response error: ${err.stack}`);
      logger.warn(`Try again after ${RETRY_DELAY / 1000}s...`);
      return (async () => {
        await new Promise((resolve) => setTimeout(resolve, RETRY_DELAY));
        return createCompletion(messages, refreshToken, _model, retryCount + 1);
      })();
    }
    throw err;
  });
}

/**
 * æµå¼å¯¹è¯è¡¥å…¨ï¼ˆçœŸæ­£çš„æµå¼å“åº” - ç«‹å³è¿”å›æµï¼Œå¼‚æ­¥ç”Ÿæˆï¼‰
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨jimengåŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletionStream(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  if (messages.length === 0) {
    throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º");
  }

  const last = messages[messages.length - 1];
  const { text: promptText, images } = parseOpenAIMessageContent(last?.content);

  // åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘æ¨¡å‹
  if (isVideoModel(_model)) {
    logger.info("æ£€æµ‹åˆ°è§†é¢‘æ¨¡å‹ï¼Œä½¿ç”¨è§†é¢‘ç”Ÿæˆï¼ˆçœŸæµå¼ï¼‰");

    // è§†é¢‘ç”Ÿæˆéœ€è¦é¦–å¸§å›¾ç‰‡
    if (!images || images.length === 0) {
      throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "è§†é¢‘ç”Ÿæˆéœ€è¦æä¾›é¦–å¸§å›¾ç‰‡");
    }

    // ğŸš€ ç«‹å³åˆ›å»ºæµå¹¶è¿”å›
    const stream = new PassThrough();

    // ç«‹å³æ¨é€åˆå§‹æ¶ˆæ¯
    stream.write(
      "data: " +
        JSON.stringify({
          id: util.uuid(),
          model: _model,
          object: "chat.completion.chunk",
          choices: [
            {
              index: 0,
              delta: { role: "assistant", content: "ğŸ¬ è§†é¢‘ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™...\nè¿™å¯èƒ½éœ€è¦1-5åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…" },
              finish_reason: null,
            },
          ],
        }) +
        "\n\n"
    );

    // ğŸ”„ å¼‚æ­¥æ‰§è¡Œè§†é¢‘ç”Ÿæˆ
    generateVideo(
      _model,
      promptText,
      {
        firstFrameImage: images[0],
      },
      refreshToken
    )
      .then((videoUrls) => {
        // æ£€æŸ¥æµæ˜¯å¦ä»ç„¶å¯å†™
        if (!stream.destroyed && stream.writable) {
          for (let i = 0; i < videoUrls.length; i++) {
            const url = videoUrls[i];
            stream.write(
              "data: " +
                JSON.stringify({
                  id: util.uuid(),
                  model: _model,
                  object: "chat.completion.chunk",
                  choices: [
                    {
                      index: i + 1,
                      delta: {
                        role: "assistant",
                        content: `\n\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼\n\n<video controls="controls">\n    ${url}\n</video>\n\n[Download Video](${url})\n\n`,
                      },
                      finish_reason: i < videoUrls.length - 1 ? null : "stop",
                    },
                  ],
                }) +
                "\n\n"
            );
          }
          stream.end("data: [DONE]\n\n");
        } else {
          logger.debug("è§†é¢‘ç”Ÿæˆå®Œæˆï¼Œä½†æµå·²å…³é—­");
        }
      })
      .catch((err) => {
        logger.error(`è§†é¢‘ç”Ÿæˆå¤±è´¥: ${err.message}`);
        // æ£€æŸ¥æµæ˜¯å¦ä»ç„¶å¯å†™
        if (!stream.destroyed && stream.writable) {
          stream.write(
            "data: " +
              JSON.stringify({
                id: util.uuid(),
                model: _model,
                object: "chat.completion.chunk",
                choices: [
                  {
                    index: 1,
                    delta: {
                      role: "assistant",
                      content: `\n\nâŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: ${err.message}\n\nè¯·æ£€æŸ¥å‚æ•°æˆ–ç¨åé‡è¯•ã€‚`,
                    },
                    finish_reason: "stop",
                  },
                ],
              }) +
              "\n\n"
          );
          stream.end("data: [DONE]\n\n");
        }
      });

    return stream;
  }

  // ğŸ¨ å›¾åƒç”Ÿæˆï¼ˆçœŸæµå¼ï¼‰
  const { model, width, height } = parseModel(_model);
  logger.info(`ğŸ¨ å¼€å§‹å›¾åƒç”Ÿæˆ (çœŸæµå¼): model=${model}, size=${width}x${height}`);

  // ğŸš€ ç«‹å³åˆ›å»ºæµå¹¶è¿”å›
  const stream = new PassThrough();

  // ç«‹å³æ¨é€åˆå§‹æ¶ˆæ¯
  stream.write(
    "data: " +
      JSON.stringify({
        id: util.uuid(),
        model: _model || model,
        object: "chat.completion.chunk",
        choices: [
          {
            index: 0,
            delta: { role: "assistant", content: "ğŸ¨ å›¾åƒç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..." },
            finish_reason: null,
          },
        ],
      }) +
      "\n\n"
  );

  // ğŸ”„ å¼‚æ­¥æ‰§è¡Œå›¾åƒç”Ÿæˆ
  generateImages(model, promptText, { width, height, images }, refreshToken)
    .then((imageUrls) => {
      // æ£€æŸ¥æµæ˜¯å¦ä»ç„¶å¯å†™
      if (!stream.destroyed && stream.writable) {
        // æ¨é€å®Œæˆæç¤º
        stream.write(
          "data: " +
            JSON.stringify({
              id: util.uuid(),
              model: _model || model,
              object: "chat.completion.chunk",
              choices: [
                {
                  index: 0,
                  delta: { role: "assistant", content: "\n\nâœ¨ å›¾åƒç”Ÿæˆå®Œæˆï¼\n\n" },
                  finish_reason: null,
                },
              ],
            }) +
            "\n\n"
        );

        // æ¨é€æ‰€æœ‰å›¾ç‰‡
        for (let i = 0; i < imageUrls.length; i++) {
          const url = imageUrls[i];
          stream.write(
            "data: " +
              JSON.stringify({
                id: util.uuid(),
                model: _model || model,
                object: "chat.completion.chunk",
                choices: [
                  {
                    index: i + 1,
                    delta: {
                      role: "assistant",
                      content: `![image_${i}](${url})\n`,
                    },
                    finish_reason: i < imageUrls.length - 1 ? null : "stop",
                  },
                ],
              }) +
              "\n\n"
          );
        }
        stream.end("data: [DONE]\n\n");
      } else {
        logger.debug("å›¾åƒç”Ÿæˆå®Œæˆï¼Œä½†æµå·²å…³é—­");
      }
    })
    .catch((err) => {
      logger.error(`å›¾åƒç”Ÿæˆå¤±è´¥: ${err.message}`);
      // æ£€æŸ¥æµæ˜¯å¦ä»ç„¶å¯å†™
      if (!stream.destroyed && stream.writable) {
        stream.write(
          "data: " +
            JSON.stringify({
              id: util.uuid(),
              model: _model || model,
              object: "chat.completion.chunk",
              choices: [
                {
                  index: 1,
                  delta: {
                    role: "assistant",
                    content: `\n\nâŒ å›¾åƒç”Ÿæˆå¤±è´¥: ${err.message}\n\nè¯·æ£€æŸ¥å‚æ•°æˆ–ç¨åé‡è¯•ã€‚`,
                  },
                  finish_reason: "stop",
                },
              ],
            }) +
            "\n\n"
        );
        stream.end("data: [DONE]\n\n");
      }
    });

  return stream;
}
