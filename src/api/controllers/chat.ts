import _ from "lodash";
import { PassThrough } from "stream";

import APIException from "@/lib/exceptions/APIException.ts";
import EX from "@/api/consts/exceptions.ts";
import logger from "@/lib/logger.ts";
import util from "@/lib/util.ts";
import { generateImages, DEFAULT_MODEL } from "./images.ts";

// æœ€å¤§é‡è¯•æ¬¡æ•°
const MAX_RETRY_COUNT = 3;
// é‡è¯•å»¶è¿Ÿ
const RETRY_DELAY = 5000;

/**
 * è§£æžæ¨¡åž‹
 *
 * @param model æ¨¡åž‹åç§°
 * @returns æ¨¡åž‹ä¿¡æ¯
 */
function parseModel(model: string) {
  const [_model, size] = model.split(":");
  
  if (!size) {
    // 4.0 æ¨¡åž‹é»˜è®¤ä½¿ç”¨ 2k å°ºå¯¸
    const is4_0Model = _model.includes("4.0");
    // 3.x æ¨¡åž‹é»˜è®¤ä½¿ç”¨ 2k å°ºå¯¸
    const is3_xModel = _model.includes("3.");
    
    let defaultDimension = 1024;
    if (is4_0Model) {
      defaultDimension = 4096;
    } else if (is3_xModel) {
      defaultDimension = 2048;
    }
    
    return {
      model: _model,
      width: defaultDimension,
      height: defaultDimension,
    };
  }

  // å¤„ç† 1k, 2k, 4k æ ¼å¼
  const kMatch = /^(\d+)k$/i.exec(size);
  if (kMatch) {
    const k = parseInt(kMatch[1]);
    const dimension = k * 1024;
    return {
      model: _model,
      width: dimension,
      height: dimension,
    };
  }

  // å¤„ç†ä¼ ç»Ÿçš„ widthxheight æ ¼å¼
  const [_, width, height] = /(\d+)[\W\w](\d+)/.exec(size) ?? [];
  return {
    model: _model,
    width: width ? Math.ceil(parseInt(width) / 2) * 2 : 1024,
    height: height ? Math.ceil(parseInt(height) / 2) * 2 : 1024,
  };
}

/**
 * è§£æž OpenAI é£Žæ ¼æ¶ˆæ¯ï¼Œæå–æ–‡æœ¬ä¸Žé¦–ä¸ªå›¾ç‰‡ URL
 */
function parseOpenAIMessageContent(content: any): { text: string; image?: string } {
  if (_.isString(content)) return { text: content };
  if (_.isArray(content)) {
    let textParts: string[] = [];
    let image: string | undefined;
    for (const item of content) {
      if (image) {
        // å·²æå–åˆ°é¦–å›¾ï¼Œä»…ç»§ç»­ç´¯ç§¯æ–‡æœ¬
        if (item?.type === "text" && _.isString(item?.text)) textParts.push(item.text);
        continue;
      }
      if (item?.type === "text" && _.isString(item?.text)) textParts.push(item.text);
      else if (
        item?.type === "image_url" &&
        item?.image_url &&
        _.isString(item?.image_url?.url)
      ) {
        image = item.image_url.url;
      }
    }
    return { text: textParts.join(""), image };
  }
  if (_.isObject(content) && _.isString((content as any).content)) return { text: (content as any).content };
  return { text: "" };
}

/**
 * åŒæ­¥å¯¹è¯è¡¥å…¨
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºŽåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨jimengåŽŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletion(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  return (async () => {
    if (messages.length === 0)
      throw new APIException(EX.API_REQUEST_PARAMS_INVALID, "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º");

    const { model, width, height } = parseModel(_model);
    logger.info(messages);

    // è§£æžæœ€åŽä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒ text + image_url
    const last = messages[messages.length - 1];
    const { text: promptText, image } = parseOpenAIMessageContent(last?.content);

    const imageUrls = await generateImages(
      model,
      promptText,
      {
        width,
        height,
        image,
      },
      refreshToken
    );

    return {
      id: util.uuid(),
      model: _model || model,
      object: "chat.completion",
      choices: [
        {
          index: 0,
          message: {
            role: "assistant",
            content: imageUrls.reduce(
              (acc, url, i) => acc + `![image_${i}](${url})\n`,
              ""
            ),
          },
          finish_reason: "stop",
        },
      ],
      usage: { prompt_tokens: 1, completion_tokens: 1, total_tokens: 2 },
      created: util.unixTimestamp(),
    };
  })().catch((err) => {
    if (retryCount < MAX_RETRY_COUNT) {
      logger.error(`Response error: ${err.stack}`);
      logger.warn(`Try again after ${RETRY_DELAY / 1000}s...`);
      return (async () => {
        await new Promise((resolve) => setTimeout(resolve, RETRY_DELAY));
        return createCompletion(messages, refreshToken, _model, retryCount + 1);
      })();
    }
    throw err;
  });
}

/**
 * æµå¼å¯¹è¯è¡¥å…¨
 *
 * @param messages å‚è€ƒgptç³»åˆ—æ¶ˆæ¯æ ¼å¼ï¼Œå¤šè½®å¯¹è¯è¯·å®Œæ•´æä¾›ä¸Šä¸‹æ–‡
 * @param refreshToken ç”¨äºŽåˆ·æ–°access_tokençš„refresh_token
 * @param assistantId æ™ºèƒ½ä½“IDï¼Œé»˜è®¤ä½¿ç”¨jimengåŽŸç‰ˆ
 * @param retryCount é‡è¯•æ¬¡æ•°
 */
export async function createCompletionStream(
  messages: any[],
  refreshToken: string,
  _model = DEFAULT_MODEL,
  retryCount = 0
) {
  return (async () => {
    const { model, width, height } = parseModel(_model);
    logger.info(messages);

    const stream = new PassThrough();

    if (messages.length === 0) {
      logger.warn("æ¶ˆæ¯ä¸ºç©ºï¼Œè¿”å›žç©ºæµ");
      stream.end("data: [DONE]\n\n");
      return stream;
    }

    stream.write(
      "data: " +
        JSON.stringify({
          id: util.uuid(),
          model: _model || model,
          object: "chat.completion.chunk",
          choices: [
            {
              index: 0,
              delta: { role: "assistant", content: "ðŸŽ¨ å›¾åƒç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..." },
              finish_reason: null,
            },
          ],
        }) +
        "\n\n"
    );

    const last = messages[messages.length - 1];
    const { text: promptText, image } = parseOpenAIMessageContent(last?.content);

    generateImages(model, promptText, { width, height, image }, refreshToken)
      .then((imageUrls) => {
        for (let i = 0; i < imageUrls.length; i++) {
          const url = imageUrls[i];
          stream.write(
            "data: " +
              JSON.stringify({
                id: util.uuid(),
                model: _model || model,
                object: "chat.completion.chunk",
                choices: [
                  {
                    index: i + 1,
                    delta: {
                      role: "assistant",
                      content: `![image_${i}](${url})\n`,
                    },
                    finish_reason: i < imageUrls.length - 1 ? null : "stop",
                  },
                ],
              }) +
              "\n\n"
          );
        }
        stream.write(
          "data: " +
            JSON.stringify({
              id: util.uuid(),
              model: _model || model,
              object: "chat.completion.chunk",
              choices: [
                {
                  index: imageUrls.length + 1,
                  delta: {
                    role: "assistant",
                    content: "å›¾åƒç”Ÿæˆå®Œæˆï¼",
                  },
                  finish_reason: "stop",
                },
              ],
            }) +
            "\n\n"
        );
        stream.end("data: [DONE]\n\n");
      })
      .catch((err) => {
        stream.write(
          "data: " +
            JSON.stringify({
              id: util.uuid(),
              model: _model || model,
              object: "chat.completion.chunk",
              choices: [
                {
                  index: 1,
                  delta: {
                    role: "assistant",
                    content: `ç”Ÿæˆå›¾ç‰‡å¤±è´¥: ${err.message}`,
                  },
                  finish_reason: "stop",
                },
              ],
            }) +
            "\n\n"
        );
        stream.end("data: [DONE]\n\n");
      });
    return stream;
  })().catch((err) => {
    if (retryCount < MAX_RETRY_COUNT) {
      logger.error(`Response error: ${err.stack}`);
      logger.warn(`Try again after ${RETRY_DELAY / 1000}s...`);
      return (async () => {
        await new Promise((resolve) => setTimeout(resolve, RETRY_DELAY));
        return createCompletionStream(
          messages,
          refreshToken,
          _model,
          retryCount + 1
        );
      })();
    }
    throw err;
  });
}
